{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('IMDB Dataset.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename(columns = {'review':'text'})\n",
    "X = dataset.iloc[:-49000,:]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "corpus = []\n",
    "for i in range(0, 1000):\n",
    "    review = X['text'][i]\n",
    "    review = re.sub(r'#[a-zA-Z0-9]+',\" \", review)\n",
    "    review = re.sub(r'@[a-zA-Z0-9]+', ' ', review)\n",
    "    review = re.sub(r'&[a-zA-Z0-9]+', ' ', review)\n",
    "    review = re.sub('[0-9]+', ' ', review)\n",
    "    review = re.sub(r'RT[\\s]+', ' ', review)\n",
    "    review = re.sub(r\"https?:\\/\\/\\S+|www\\S+|\", \"\", review)\n",
    "    review = re.sub(r'\\\\[a-zA-Z0-9]+', ' ', review)\n",
    "    review = re.sub(r'^[a-zA-Z0-9]+',\" \", review)\n",
    "    review = re.sub(r'[^a-zA-Z0-9]+',\" \", review)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['cleaned'] = corpus\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('sentiwordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "pos=neg=obj=count=0\n",
    "\n",
    "postagging = []\n",
    "\n",
    "for review in corpus:\n",
    "    list = word_tokenize(review)\n",
    "    postagging.append(nltk.pos_tag(list))\n",
    "\n",
    "X['pos_tags'] = postagging\n",
    "\n",
    "def penn_to_wn(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    return None\n",
    "\n",
    "\n",
    "# Returns list of pos-neg and objective score. But returns empty list if not present in senti wordnet.\n",
    "def get_sentiment(word,tag):\n",
    "    wn_tag = penn_to_wn(tag)\n",
    "    \n",
    "    if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
    "        return []\n",
    "\n",
    "    #Lemmatization\n",
    "    lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "    if not lemma:\n",
    "        return []\n",
    "\n",
    "    #Synset is a special kind of a simple interface that is present in NLTK to look up words in WordNet. \n",
    "    #Synset instances are the groupings of synonymous words that express the same concept. \n",
    "    #Some of the words have only one Synset and some have several.\n",
    "    synsets = wn.synsets(word, pos=wn_tag)\n",
    "    if not synsets:\n",
    "        return []\n",
    "\n",
    "    # Take the first sense, the most common\n",
    "    synset = synsets[0]\n",
    "    swn_synset = swn.senti_synset(synset.name())\n",
    "\n",
    "    return [synset.name(), swn_synset.pos_score(),swn_synset.neg_score(),swn_synset.obj_score()]\n",
    "\n",
    "    pos=neg=obj=count=0\n",
    "    \n",
    "    ###################################################################################\n",
    "senti_score = []\n",
    "\n",
    "for pos_val in X['pos_tags']:\n",
    "    senti_val = [get_sentiment(x,y) for (x,y) in pos_val]\n",
    "    for score in senti_val:\n",
    "        try:\n",
    "            pos = pos + score[1]  #positive score is stored at 2nd position\n",
    "            neg = neg + score[2]  #negative score is stored at 3rd position\n",
    "        except:\n",
    "            continue\n",
    "    senti_score.append(pos - neg)\n",
    "    pos=neg=0    \n",
    "    \n",
    "X['senti_score'] = senti_score\n",
    "\n",
    "\n",
    "X.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall=[]\n",
    "for i in range(len(X)):\n",
    "    if X['senti_score'][i]>= 0:\n",
    "        overall.append('Positive')\n",
    "    elif X['senti_score'][i]<0:\n",
    "        overall.append('Negative')\n",
    "    \n",
    "X['Overall Sentiment']=overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Sentiment Analysis Using SentiWordnet\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Counts\")\n",
    "X['Overall Sentiment'].value_counts().plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectivity(review):\n",
    "    return TextBlob(review).sentiment.subjectivity\n",
    "def polarity(review):\n",
    "    return TextBlob(review).sentiment.polarity\n",
    "Polarity=[]\n",
    "Subjectivity=[]\n",
    "for i in range(0,len( X)):\n",
    "    Polarity.append(polarity(corpus[i]))\n",
    "    Subjectivity.append(subjectivity(corpus[i]))\n",
    "\n",
    "Polarity = np.array(Polarity)\n",
    "Subjectivity = np.array(Subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentiment=[]\n",
    "for i in range(0,len(X)):\n",
    "    if Polarity[i]>= 0:\n",
    "        Sentiment.append('Positive')\n",
    "    elif Polarity[i]< 0:\n",
    "        Sentiment.append('Negative')\n",
    "    \n",
    "X[\"Senti\"]=Sentiment\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Sentiment Analysis Using TextBlob\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Counts\")\n",
    "X['Senti'].value_counts().plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "cader=[]\n",
    "for i in range(0,len( X)):\n",
    "    cader.append(vader.polarity_scores(corpus[i]))\n",
    "\n",
    "\n",
    "\n",
    "X[\"Vader_Sentiment\"] = cader\n",
    "cader\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Vader_Senti = []\n",
    "\n",
    "for i in range(0,len( X)):\n",
    "    if cader[i]['compound']>= 0 :\n",
    "        Vader_Senti.append(\"Positive\")\n",
    "    elif cader[i]['compound']<0 :\n",
    "        Vader_Senti.append(\"Negative\")\n",
    "    \n",
    "        \n",
    "X[\"Vader Sentiment\"] = Vader_Senti\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Sentiment Analysis Using VADER\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Counts\")\n",
    "X[\"Vader Sentiment\"].value_counts().plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Original\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Counts\")\n",
    "X[\"sentiment\"].value_counts().plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,1000):\n",
    "    if X['sentiment'][i] == 'positive':\n",
    "        X['sentiment'][i]=1\n",
    "    elif X['sentiment'][i] == 'negative':\n",
    "        X['sentiment'][i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,1000):\n",
    "    if X['Overall Sentiment'][i] == 'Positive':\n",
    "        X['Overall Sentiment'][i]=1\n",
    "    elif X['Overall Sentiment'][i] == 'Negative':\n",
    "        X['Overall Sentiment'][i]=0\n",
    "        \n",
    "for i in range(0,1000):\n",
    "    if X['Senti'][i] == 'Positive':\n",
    "        X['Senti'][i]=1\n",
    "    elif X['Senti'][i] == 'Negative':\n",
    "        X['Senti'][i]=0\n",
    "        \n",
    "for i in range(0,1000):\n",
    "    if X['Vader Sentiment'][i] == 'Positive':\n",
    "        X['Vader Sentiment'][i]=1\n",
    "    elif X['Vader Sentiment'][i] == 'Negative':\n",
    "        X['Vader Sentiment'][i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ori=[]\n",
    "TxtB =[]\n",
    "SentiWrd = []\n",
    "Vad = []\n",
    "\n",
    "Ori = X['sentiment'].astype(float)\n",
    "TxtB = X['Senti'].astype(float)\n",
    "SentiWrd = X['Overall Sentiment'].astype(float)\n",
    "Vad = X['Vader Sentiment'].astype(float)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"              TextBlob Classifiaction Report\")\n",
    "print(classification_report(Ori,TxtB))\n",
    "print(\"              SentiWordNet Classifiaction Report\")\n",
    "print(classification_report(Ori,SentiWrd))\n",
    "print(\"              Vader Classifiaction Report\")\n",
    "print(classification_report(Ori,Vad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
